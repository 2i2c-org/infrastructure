name: azure.carbonplan
provider: kubeconfig
kubeconfig:
  file: secrets/azure.carbonplan.yaml
support:
  config:
    nvidiaDevicePlugin:
      azure:
        enabled: true
    prometheus:
      server:
        resources:
          requests:
            cpu: 1
            memory: 4Gi
          limits:
            cpu: 4
            memory: 8Gi
    grafana:
      ingress:
        hosts:
          - grafana.azure.carbonplan.2i2c.cloud
        tls:
          - secretName: grafana-tls
            hosts:
              - grafana.azure.carbonplan.2i2c.cloud
hubs:
  - name: staging
    domain: staging.azure.carbonplan.2i2c.cloud
    helm_chart: daskhub
    auth0:
      # connection update? Also ensure the basehub Helm chart is provided a
      # matching value for jupyterhub.custom.2i2c.add_staff_user_ids_of_type!
      connection: github
    config: &carbonPlanHubConfig
      basehub:
        azureFile:
          enabled: false
        nfs:
          enabled: true
          pv:
            # Recommended options from the Azure Portal UI for mounting the share
            mountOptions:
              - vers=4
              - minorversion=1
              - sec=sys
            serverIP: 2i2ccarbonplanhubstorage.file.core.windows.net
            # Trailing slash is important!
            baseShareName: /2i2ccarbonplanhubstorage/homes/
        jupyterhub:
          custom:
            2i2c:
              add_staff_user_ids_to_admin_users: true
              add_staff_user_ids_of_type: "github"
            homepage:
              templateVars:
                org:
                  name: Carbon Plan
                  logo_url: https://pbs.twimg.com/profile_images/1262387945971101697/5q_X3Ruk_400x400.jpg
                  url: https://carbonplan.org
                designed_by:
                  name: 2i2c
                  url: https://2i2c.org
                operated_by:
                  name: 2i2c
                  url: https://2i2c.org
                funded_by:
                  name: Carbon Plan
                  url: https://carbonplan.org
          singleuser:
            initContainers:
              # Need to explicitly fix ownership here, since Azure File doesn't do anonuid
              - name: volume-mount-ownership-fix
                image: busybox
                command:
                  [
                    "sh",
                    "-c",
                    "id && chown 1000:1000 /home/jovyan && ls -lhd /home/jovyan",
                  ]
                securityContext:
                  runAsUser: 0
                volumeMounts:
                  - name: home
                    mountPath: /home/jovyan
                    subPath: "{username}"
            image:
              name: carbonplan/cmip6-downscaling-single-user
              tag: latest
            profileList:
              # The mem-guarantees are here so k8s doesn't schedule other pods
              # on these nodes.
              - display_name: "Small: E2s v4"
                description: "~2 CPU, ~15G RAM"
                kubespawner_override:
                  # Explicitly unset mem_limit, so it overrides the default memory limit we set in
                  # basehub/values.yaml
                  mem_limit: null
                  mem_guarantee: 12G
                  node_selector:
                    hub.jupyter.org/node-size: Standard_E2s_v4
              - display_name: "Medium: E4s v4"
                description: "~4 CPU, ~30G RAM"
                kubespawner_override:
                  mem_limit: null
                  mem_guarantee: 27G
                  node_selector:
                    hub.jupyter.org/node-size: Standard_E4s_v4
              - display_name: "Large: E8s v4"
                description: "~8 CPU, ~60G RAM"
                kubespawner_override:
                  mem_limit: null
                  mem_guarantee: 55G
                  node_selector:
                    hub.jupyter.org/node-size: Standard_E8s_v4
              - display_name: "Huge: E32s v4"
                description: "~32 CPU, ~256G RAM"
                kubespawner_override:
                  mem_limit: null
                  mem_guarantee: 235G
                  node_selector:
                    hub.jupyter.org/node-size: Standard_E32s_v4
              - display_name: "Very Huge: M64s v2"
                description: "~64 CPU, ~1024G RAM"
                kubespawner_override:
                  mem_limit: null
                  mem_guarantee: 950G
                  node_selector:
                    hub.jupyter.org/node-size: Standard_M64s_v2
              - display_name: "Very Very Huge: M128s v2"
                description: "~128 CPU, ~2048G RAM"
                kubespawner_override:
                  mem_limit: null
                  mem_guarantee: 1950G
                  node_selector:
                    hub.jupyter.org/node-size: Standard_M128s_v2
              - display_name: "GPU: NC24s v3"
                description: "~24 CPU, ~90G RAM"
                kubespawner_override:
                  image: "pangeo/ml-notebook:master"
                  mem_limit: null
                  mem_guarantee: 90G
                  extra_resource_limits:
                    nvidia.com/gpu: "1"
                  node_selector:
                    hub.jupyter.org/node-size: Standard_NC24s_v3
                    hub.jupyter.org/sku: gpu
          scheduling:
            userPlaceholder:
              enabled: false
              replicas: 0
            userScheduler:
              enabled: false
          proxy:
            chp:
              resources:
                requests:
                  cpu: 0.5
                  memory: 256Mi
                limits:
                  cpu: 1
                  memory: 4Gi
              nodeSelector: {}
          hub:
            resources:
              requests:
                cpu: 0.5
                memory: 256Mi
              limits:
                cpu: 1
                memory: 4Gi
            allowNamedServers: true
            readinessProbe:
              enabled: false
            nodeSelector: {}
            config:
              Authenticator:
                allowed_users: &users
                  - jhamman
                  - norlandrhagen
                admin_users: *users
      dask-gateway:
        traefik:
          resources:
            requests:
              cpu: 0.5
              memory: 512Mi
            limits:
              cpu: 2
              memory: 4Gi
        controller:
          resources:
            requests:
              cpu: 0.5
              memory: 512Mi
            limits:
              cpu: 2
              memory: 4Gi
        gateway:
          resources:
            requests:
              cpu: 0.5
              memory: 512Mi
            limits:
              cpu: 2
              memory: 4Gi
  - name: prod
    domain: prod.azure.carbonplan.2i2c.cloud
    helm_chart: daskhub
    auth0:
      # connection update? Also ensure the basehub Helm chart is provided a
      # matching value for jupyterhub.custom.2i2c.add_staff_user_ids_of_type!
      connection: github
    config: *carbonPlanHubConfig
