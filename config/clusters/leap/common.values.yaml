basehub:
  nfs:
    enabled: true
    pv:
      mountOptions:
        - soft
        - noatime
      # Google FileStore IP
      serverIP: 10.104.103.242
      # Name of Google Filestore share
      baseShareName: /homes/
  jupyterhub:
    proxy:
      https:
        enabled: false
    custom:
      2i2c:
        add_staff_user_ids_to_admin_users: true
        add_staff_user_ids_of_type: "github"
      homepage:
        templateVars:
          org:
            name: LEAP
            url: https://leap-stc.github.io
            logo_url: https://leap-stc.github.io/_static/LEAP_logo.png
          designed_by:
            name: 2i2c
            url: https://2i2c.org
          operated_by:
            name: 2i2c
            url: https://2i2c.org
          funded_by:
            name: LEAP
            url: https://leap-stc.github.io
    hub:
      allowNamedServers: true
      config:
        Authenticator:
          enable_auth_state: true
          # This hub uses GitHub Teams auth and so we don't set
          # allowed_users in order to not deny access to valid members of
          # the listed teams. These people should have admin access though.
          admin_users:
            - rabernat
        JupyterHub:
          authenticator_class: github
        GitHubOAuthenticator:
          populate_teams_in_auth_state: true
          allowed_organizations:
            - leap-stc:leap-pangeo-users
            - 2i2c-org:tech-team
          scope:
            - read:org
    singleuser:
      image:
        name: pangeo/pangeo-notebook
        tag: 39778b5
      extraEnv:
        GH_SCOPED_CREDS_CLIENT_ID: "Iv1.0c7df3d4b3191b2f"
        GH_SCOPED_CREDS_APP_URL: https://github.com/apps/leap-hub-push-access
      profileList:
        # The mem-guarantees are here so k8s doesn't schedule other pods
        # on these nodes. They need to be just under total allocatable
        # RAM on a node, not total node capacity. Values calculated using
        # https://learnk8s.io/kubernetes-instance-calculator
        - display_name: "Small"
          description: 5GB RAM, 2 CPUs
          default: true
          allowed_teams:
            - leap-stc:leap-pangeo-users
            - 2i2c-org:tech-team
          kubespawner_override:
            mem_limit: 7G
            mem_guarantee: 4.5G
            node_selector:
              node.kubernetes.io/instance-type: n1-standard-2
        - display_name: Medium
          description: 11GB RAM, 4 CPUs
          allowed_teams:
            - leap-stc:leap-pangeo-users
            - 2i2c-org:tech-team
          kubespawner_override:
            mem_limit: 15G
            mem_guarantee: 11G
            node_selector:
              node.kubernetes.io/instance-type: n1-standard-4
        - display_name: Large
          description: 24GB RAM, 8 CPUs
          allowed_teams:
            - leap-stc:leap-pangeo-education
            - leap-stc:leap-pangeo-research
            - 2i2c-org:tech-team
          kubespawner_override:
            mem_limit: 30G
            mem_guarantee: 24G
            node_selector:
              node.kubernetes.io/instance-type: n1-standard-8
        - display_name: Huge
          description: 52GB RAM, 16 CPUs
          allowed_teams:
            - leap-stc:leap-pangeo-research
            - 2i2c-org:tech-team
          kubespawner_override:
            mem_limit: 60G
            mem_guarantee: 52G
            node_selector:
              node.kubernetes.io/instance-type: n1-standard-16
        - display_name: Large + Nvidia K80 GPU
          description: 24GB RAM, 8 CPUs, Nvidia Tesla K80 GPU
          allowed_teams:
            - leap-stc:leap-pangeo-research
            - 2i2c-org:tech-team
          kubespawner_override:
            image: "pangeo/ml-notebook:39778b5"
            mem_limit: 30G
            mem_guarantee: 24G
            node_selector:
              node.kubernetes.io/instance-type: n1-standard-8
            environment:
              NVIDIA_DRIVER_CAPABILITIES: compute,utility
            extra_resource_limits:
              nvidia.com/gpu: "1"
      initContainers:
        # Need to explicitly fix ownership here, since EFS doesn't do anonuid
        - name: volume-mount-ownership-fix
          image: busybox
          command: ["sh", "-c", "id && chown 1000:1000 /home/jovyan && ls -lhd /home/jovyan"]
          securityContext:
            runAsUser: 0
          volumeMounts:
            - name: home
              mountPath: /home/jovyan
              subPath: "{username}"
dask-gateway:
  gateway:
    backend:
      scheduler:
        cores:
          request: 0.8
          limit: 1
        memory:
          request: 1G
          limit: 2G
