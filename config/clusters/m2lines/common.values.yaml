basehub:
  nfs:
    enabled: true
    pv:
      mountOptions:
        - soft
        - noatime
      # Google FileStore IP
      serverIP: 10.98.223.138
      # Name of Google Filestore share
      baseShareName: /homes/
  jupyterhub:
    proxy:
      https:
        enabled: false
    custom:
      2i2c:
        add_staff_user_ids_to_admin_users: true
        add_staff_user_ids_of_type: "github"
      homepage:
        templateVars:
          org:
            name: M²LInES
            url: https://m2lines.github.io/
            logo_url: https://m2lines.github.io/images/newlogo.png
          designed_by:
            name: 2i2c
            url: https://2i2c.org
          operated_by:
            name: 2i2c
            url: https://2i2c.org
          funded_by:
            name: M²LInES
            url: https://m2lines.github.io/
    hub:
      allowNamedServers: true
      config:
        Authenticator:
          # This hub uses GitHub Teams auth and so we don't set
          # allowed_users in order to not deny access to valid members of
          # the listed teams. These people should have admin access though.
          admin_users:
            - rabernat
            - johannag126
        JupyterHub:
          authenticator_class: github
        GitHubOAuthenticator:
          allowed_organizations:
            - m2lines
            - 2i2c-org:hub-access-for-2i2c-staff
          scope:
            - read:org
    singleuser:
      extraFiles:
        jupyter_notebook_config.json:
          data:
            MappingKernelManager:
              # Cull idle kernels after 24h (24 * 60 * 60), to see if that
              # makes the experience better for research hubs.
              # Ref https://2i2c.freshdesk.com/a/tickets/243
              cull_idle_timeout: 86400
      extraEnv:
        GH_SCOPED_CREDS_CLIENT_ID: "Iv1.1c4d967ffc205f98"
        GH_SCOPED_CREDS_APP_URL: https://github.com/apps/m2lines-pangeo-hub-push-access
        # Temporarily set for *all* pods, including pods without any GPUs,
        # to work around https://github.com/2i2c-org/infrastructure/issues/1530
        NVIDIA_DRIVER_CAPABILITIES: compute,utility
      # User image repo: https://github.com/pangeo-data/pangeo-docker-images
      image:
        name: pangeo/pangeo-notebook
        tag: "ebeb9dd"
      profileList:
        # The mem-guarantees are here so k8s doesn't schedule other pods
        # on these nodes. They need to be just under total allocatable
        # RAM on a node, not total node capacity. Values calculated using
        # https://learnk8s.io/kubernetes-instance-calculator
        - display_name: "Small"
          description: 5GB RAM, 2 CPUs
          default: true
          kubespawner_override:
            mem_limit: 7G
            mem_guarantee: 4.5G
            node_selector:
              node.kubernetes.io/instance-type: n1-standard-2
          profile_options: &profile_options
            image:
              display_name: Image
              choices:
                pangeo:
                  display_name: Base Pangeo Notebook
                  default: true
                  slug: "pangeo"
                  kubespawner_override:
                    image: "pangeo/pangeo-notebook:ebeb9dd"
                tensorflow:
                  display_name: Pangeo Tensorflow ML Notebook
                  slug: "tensorflow"
                  kubespawner_override:
                    image: "pangeo/ml-notebook:ebeb9dd"
                pytorch:
                  display_name: Pangeo PyTorch ML Notebook
                  slug: "pytorch"
                  kubespawner_override:
                    image: "pangeo/pytorch-notebook:ebeb9dd"
        - display_name: Medium
          description: 11GB RAM, 4 CPUs
          kubespawner_override:
            mem_limit: 15G
            mem_guarantee: 11G
            node_selector:
              node.kubernetes.io/instance-type: n1-standard-4
          profile_options: *profile_options
        - display_name: Large
          description: 24GB RAM, 8 CPUs
          kubespawner_override:
            mem_limit: 30G
            mem_guarantee: 24G
            node_selector:
              node.kubernetes.io/instance-type: n1-standard-8
          profile_options: *profile_options
        - display_name: Huge
          description: 52GB RAM, 16 CPUs
          kubespawner_override:
            mem_limit: 60G
            mem_guarantee: 52G
            node_selector:
              node.kubernetes.io/instance-type: n1-standard-16
          profile_options: *profile_options
        - display_name: Large + GPU
          slug: gpu
          description: 24GB RAM, 8 CPUs
          profile_options:
            image:
              display_name: Image
              choices:
                tensorflow:
                  display_name: Pangeo Tensorflow ML Notebook
                  slug: "tensorflow"
                  kubespawner_override:
                    image: "pangeo/ml-notebook:ebeb9dd"
                pytorch:
                  display_name: Pangeo PyTorch ML Notebook
                  default: true
                  slug: "pytorch"
                  kubespawner_override:
                    image: "pangeo/pytorch-notebook:ebeb9dd"
          kubespawner_override:
            node_selector:
              cloud.google.com/gke-nodepool: nb-gpu-t4
            mem_limit: 30G
            mem_guarantee: 24G
            extra_resource_limits:
              nvidia.com/gpu: "1"
dask-gateway:
  gateway:
    backend:
      scheduler:
        cores:
          request: 0.8
          limit: 1
        memory:
          request: 1G
          limit: 2G
