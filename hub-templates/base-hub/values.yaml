etcJupyter:
  jupyter_notebook_config.json:
    # if a user leaves a notebook with a running kernel,
    # the effective idle timeout will typically be CULL_TIMEOUT + CULL_KERNEL_TIMEOUT
    # as culling the kernel will register activity,
    # resetting the no_activity timer for the server as a whole
    MappingKernelManager:
      # shutdown kernels after no activity
      cull_idle_timeout: 3600
      # check for idle kernels this often
      cull_interval: 300
      # a kernel with open connections but no activity still counts as idle
      # this is what allows us to shutdown servers
      # when people leave a notebook open and wander off
      cull_connected: true

nfsPVC:
  enabled: true
  nfs:
    serverIP: nfs-server-01
    shareName: /export/home-01

jupyterhub:
  ingress:
    enabled: true
    annotations:
      nginx.ingress.kubernetes.io/proxy-body-size: 256m
      kubernetes.io/ingress.class: nginx
      cert-manager.io/cluster-issuer: letsencrypt-prod
  scheduling:
    userPlaceholder:
      enabled: true
      replicas: 1
    podPriority:
      enabled: true
      globalDefault: false
      defaultPriority: 0
      userPlaceholderPriority: -10
    userScheduler:
      enabled: true
      nodeSelector:
        hub.jupyter.org/pool-name: core-pool
      resources:
        requests:
          # FIXME: Just unset this?
          cpu: 0.01
          memory: 64Mi
        limits:
          memory: 1G
  prePuller:
    continuous:
      enabled: false
    hook:
      enabled: false
  proxy:
    service:
      type: ClusterIP
    chp:
      nodeSelector:
        hub.jupyter.org/pool-name: core-pool
      resources:
        requests:
          # FIXME: We want no guarantees here!!!
          # This is lowest possible value
          cpu: 0.01
          memory: 64Mi
        limits:
          memory: 1Gi
    traefik:
      nodeSelector:
        hub.jupyter.org/pool-name: core-pool
      resources:
        requests:
          memory: 64Mi
        limits:
          memory: 1Gi
    https:
      letsencrypt:
        contactEmail: yuvipanda@gmail.com
    networkPolicy:
      enabled: true
      ingress:
      - from:
        - namespaceSelector:
            matchLabels:
              name: support
        - podSelector:
            matchLabels:
              hub.jupyter.org/network-access-proxy-http: "true"
        ports:
        - port: http
  singleuser:
    admin:
      extraVolumeMounts:
      - name: home
        mountPath: /home/jovyan/shared-readwrite
        subPath: _shared
    startTimeout: 600 # 10 mins, because sometimes we have too many new nodes coming up together
    defaultUrl: /tree
    nodeSelector:
      hub.jupyter.org/pool-name: user-pool
    image:
      name: set_automatically_by_automation
      tag: 4066a62
    storage:
      type: static
      static:
        pvcName: home-nfs
        subPath: '{username}'
      extraVolumeMounts:
      - name: home
        mountPath: /home/jovyan/shared
        subPath: _shared
        readOnly: true
    memory:
      guarantee: 256M
      limit: 1G
    networkPolicy:
      # In clusters with NetworkPolicy enabled, do not
      # allow outbound internet access that's not DNS, HTTP or HTTPS
      # We can override this on a case to case basis where
      # required.
      enabled: true
      egress:
        - ports:
            - port: 53
              protocol: UDP
        - ports:
            - port: 80
              protocol: TCP
        - ports:
            - port: 443
              protocol: TCP
  auth:
    type: dummy
  hub:
    nodeSelector:
      hub.jupyter.org/pool-name: core-pool
    networkPolicy:
      enabled: true
      ingress:
        - from:
            - namespaceSelector:
                matchLabels:
                  name: support
              podSelector:
                matchLabels:
                  app: prometheus
                  component: server
          ports:
            - port: http
              protocol: TCP
    resources:
      requests:
        # Very small unit, since we don't want any CPU guarantees
        cpu: 0.01
        memory: 128Mi
      limits:
        memory: 2Gi
    extraConfig:
      01-working-dir: |
        # Make sure working directory is ${HOME}
        # hubploy has a bug where it unconditionally puts workingdir to be /srv/repo
        c.KubeSpawner.working_dir = '/home/jovyan'
      02-prometheus: |
        # Allow unauthenticated prometheus requests
        # Otherwise our prometheus server can't get to these
        c.JupyterHub.authenticate_prometheus = False
      03-no-setuid: |
        c.KubeSpawner.extra_container_config = {
          'securityContext': {
            # Explicitly disallow setuid binaries from working inside the container
            'allowPrivilegeEscalation': False
          }
        }
      04-custom-theme: |
        from z2jh import get_config
        c.JupyterHub.template_paths = ['/usr/local/share/jupyterhub/custom_templates/']

        c.JupyterHub.template_vars = {
          'custom':get_config('homepage.templateVars')
        }
      05-custom-admin: |
        from z2jh import get_config
        from kubespawner import KubeSpawner
        class CustomSpawner(KubeSpawner):
          def start(self, *args, **kwargs):
            custom_admin = get_config('singleuser.admin', {})
            if custom_admin and self.user.admin:
                self.init_containers += custom_admin.get('initContainers', [])
                self.volume_mounts += custom_admin.get('extraVolumeMounts', [])

            return super().start(*args, **kwargs)

        c.JupyterHub.spawner_class = CustomSpawner
docsService:
  enabled: true
  nginx.conf: |
    events {}
    http {
      server {
          root /usr/local/share/docs;
          location /foo {
              autoindex on;
          }
      }
    }
  initContainers:
    - name: docs-clone
      image: alpine/git
      args: 
        - clone
        - --depth=1
        - --single-branch
        - --
        - https://github.com/2i2c-org/pilot-homepage
        - /srv/docs
      securityContext:
          runAsUser: 1000
          allowPrivilegeEscalation: False
          readOnlyRootFilesystem: True
      volumeMounts:
        - name: docs
          mountPath: /srv/docs
  extraContainers:
    - name: docs-sync
      image: alpine/git
      workingDir: /srv/docs
      command: 
        - /bin/sh
      args:
        - -c
        - "while true; do git fetch origin; git reset --hard origin/master; sleep\
          \ 5m; done"
      securityContext:
        runAsUser: 1000
        allowPrivilegeEscalation: False
        readOnlyRootFilesystem: True
      volumeMounts:
        - name: docs
          mountPath: /srv/docs
  extraVolumes:
    - name: docs
      emptyDir: {}
  extraVolumeMounts:
    - mountPath: /usr/local/share/docs
      name: docs
