name: Deploy and test hubs

on:
  push:
    branches:
      - master
    paths:
      - deployer/**
      - requirements.txt
      - .github/actions/setup-deploy/**
      - "**.yaml"
      # We no longer trigger on this file since it does not contain any logic
      # concerning setting up the clusters for deploy. This now all lives in the
      # setup-deploy local action
      # - .github/workflows/deploy-hubs.yaml
  pull_request:
    branches:
      - master
    paths:
      - deployer/**
      - requirements.txt
      - .github/actions/setup-deploy/**
      - "**.yaml"
      # We no longer trigger on this file since it does not contain any logic
      # concerning setting up the clusters for deploy. This now all lives in the
      # setup-deploy local action
      # - .github/workflows/deploy-hubs.yaml

# When multiple PRs triggering this workflow are merged, queue them instead
# of running them in parallel
# https://github.blog/changelog/2021-04-19-github-actions-limit-workflow-run-or-job-concurrency/
concurrency: deploy

# This environment variable triggers the deployer to colourise print statments in the
# GitHug Actions logs for easy reading
env:
  TERM: xterm

jobs:
  # This job runs in Pull Requests and on pushes to the default branch. It identifies
  # which files have been aded or modified by recent GitHub activity and parsed a list
  # to the generate-helm-upgrade-jobs function of the deployer. This function generates
  # two lists of dictionaries, which can be read by GitHub Actions as matrix jobs. The
  # first set of jobs describes which clusters need their support chart and/or staging
  # hub upgraded; and the second set of jobs describe which production hubs require
  # upgrading. These two lists are set as job outputs using ::set-output to be consumed
  # by the later jobs. They are also pretty-printed in a human-readable format to the
  # logs.
  generate-jobs:
    runs-on: ubuntu-latest
    outputs:
      support-and-staging-matrix-jobs: ${{ steps.generate-jobs.outputs.support-and-staging-matrix-jobs }}
      prod-hub-matrix-jobs: ${{ steps.generate-jobs.outputs.prod-hub-matrix-jobs }}

    steps:
      - name: Checkout repo
        uses: actions/checkout@v3
        with:
          # Fetch-depth is required for the jitterbit/get-changed-files action
          # https://github.com/jitterbit/get-changed-files/issues/24#issuecomment-1047442168
          fetch-depth: 0

      - name: Install Python 3.9
        uses: actions/setup-python@v3
        with:
          python-version: "3.9"

      # There will almost never be a cache hit on the cache key when this job is
      # run, as it is the first of all jobs in this workflow. An exception is if
      # this job is re-attempted as part of the same workflow run after
      # succeeding previously.
      - name: Save pip's install cache on job completion
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          # key determines if we define or re-use an existing cache or not. Our
          # key ensure we cache within a workflow run and its attempts, but not
          # between workflow runs.
          key: "${{ github.run_id }}"

      - name: Install deployer script's Python dependencies
        run: |
          pip install -r requirements.txt
          pip list

      - name: Identify files that have been added or modified
        uses: jitterbit/get-changed-files@v1
        id: changed-files
        with:
          format: space-delimited
          token: ${{ secrets.GITHUB_TOKEN }}

      # TODO: Post the pretty print output of this step as a comment on the Pull Request.
      # Do this in a Netlify-style way where if a comment already exists, it is updated
      # instead of generating a new comment.
      - name: Generate matrix jobs
        id: generate-jobs
        run: |
          python deployer generate-helm-upgrade-jobs "${{ steps.changed-files.outputs.added_modified }}"

  # This job upgrades the support chart, staging hub, and dask-staging hub (if present)
  # for clusters in parallel, if those upgrades are required. This job needs the
  # `generate-jobs` job to have completed and set an output to the
  # `support-and-staging-matrix-jobs` variable name. It's inputs are a list of
  # dictionaries with the keys cluster_name, provider, upgrade_support, and
  # upgrade_staging for each cluster that requires it.
  upgrade-support-and-staging:
    runs-on: ubuntu-latest
    needs: [generate-jobs]

    # We declare outputs indicating the job failed status of a specific job
    # variation. We are currently required to do this in a hardcoded fashion,
    # see this post for feature requests for this to be improved:
    # https://github.community/t/bug-jobs-output-should-return-a-list-for-a-matrix-job/128626/32?u=consideratio
    #
    # IMPORTANT: names can include alphanumerics, '-', and '_', but not '.', so
    #            we replace '.' for '-' in cluster names.
    #
    outputs:
      failure_2i2c: "${{ steps.declare-failure-status.outputs.failure_2i2c }}"
      failure_azure-carbonplan: "${{ steps.declare-failure-status.outputs.failure_azure-carbonplan }}"
      failure_carbonplan: "${{ steps.declare-failure-status.outputs.failure_carbonplan }}"
      failure_cloudbank: "${{ steps.declare-failure-status.outputs.failure_cloudbank }}"
      failure_farallon: "${{ steps.declare-failure-status.outputs.failure_farallon }}"
      failure_leap: "${{ steps.declare-failure-status.outputs.failure_leap }}"
      failure_meom-ige: "${{ steps.declare-failure-status.outputs.failure_meom-ige }}"
      failure_openscapes: "${{ steps.declare-failure-status.outputs.failure_openscapes }}"
      failure_pangeo-hubs: "${{ steps.declare-failure-status.outputs.failure_pangeo-hubs }}"
      failure_utoronto: "${{ steps.declare-failure-status.outputs.failure_utoronto }}"
      failure_uwhackweeks: "${{ steps.declare-failure-status.outputs.failure_uwhackweeks }}"

    # Only run this job on pushes to the default branch and when the job output is not
    # an empty list
    if: |
      (github.event_name == 'push' && contains(github.ref, 'master')) &&
      needs.generate-jobs.outputs.support-and-staging-matrix-jobs != '[]'
    strategy:
      # Don't stop other deployments if one fails
      fail-fast: false
      matrix:
        jobs: ${{ fromJson(needs.generate-jobs.outputs.support-and-staging-matrix-jobs) }}

    steps:
      - name: Checkout repo
        uses: actions/checkout@v3

      - name: Setup deploy for ${{ matrix.jobs.cluster_name }}
        uses: ./.github/actions/setup-deploy
        with:
          provider: ${{ matrix.jobs.provider }}
          GCP_KMS_DECRYPTOR_KEY: ${{ secrets.GCP_KMS_DECRYPTOR_KEY }}

      - name: Upgrade support chart on cluster ${{ matrix.jobs.cluster_name }}
        if: matrix.jobs.upgrade_support
        run: |
          python deployer deploy-support ${{ matrix.jobs.cluster_name }}

      - name: Upgrade staging hub on cluster ${{ matrix.jobs.cluster_name }}
        if: matrix.jobs.upgrade_staging
        run: |
          python deployer deploy ${{ matrix.jobs.cluster_name }} staging

      # Retry action: https://github.com/marketplace/actions/retry-step
      - name: Run health check for staging hub on cluster ${{ matrix.jobs.cluster_name }}
        if: matrix.jobs.upgrade_staging
        uses: nick-fields/retry@v2.6.0
        with:
          timeout_minutes: 10
          max_attempts: 2
          command: |
            python deployer run-hub-health-check ${{ matrix.jobs.cluster_name }} staging

      - name: Upgrade dask-staging hub on cluster ${{ matrix.jobs.cluster_name }} if it exists
        if: matrix.jobs.upgrade_staging && matrix.jobs.cluster_name == '2i2c'
        run: |
          python deployer deploy ${{ matrix.jobs.cluster_name }} dask-staging

      # Retry action: https://github.com/marketplace/actions/retry-step
      - name: Run health check for dask-staging hub on cluster ${{ matrix.jobs.cluster_name }} if it exists
        if: matrix.jobs.upgrade_staging && matrix.jobs.cluster_name == '2i2c'
        uses: nick-fields/retry@v2.6.0
        with:
          timeout_minutes: 10
          max_attempts: 2
          command: |
            python deployer run-hub-health-check ${{ matrix.jobs.cluster_name }} dask-staging

      - name: Declare failure status
        id: declare-failure-status
        if: always()
        shell: python
        run: |
          name = "${{ matrix.jobs.cluster_name }}".replace(".", "-")
          failure = "${{ job.status == 'failure' }}"
          print(f"::set-output name=failure_{name}::{failure}")

  # This jobs reduces the initially planned prod-hub-matrix-jobs deployments by
  # filtering out any deployment to a cluster with a failed support-and-staging
  # job.
  filter-generate-jobs:
    runs-on: ubuntu-latest
    needs: [generate-jobs, upgrade-support-and-staging]
    # Only run this job on pushes to the default branch and when the job output is not
    # an empty list
    #
    # always() is added as it seems to be a magic function to ensure a job can
    # run at all without being skipped if a previous job has had any failures.
    #
    if: |
      always() &&
      (github.event_name == 'push' && contains(github.ref, 'master')) &&
      needs.generate-jobs.outputs.prod-hub-matrix-jobs != '[]'

    outputs:
      filtered-prod-hub-matrix-jobs: ${{ steps.filter-generate-jobs.outputs.filtered-prod-hub-matrix-jobs }}

    steps:
      # This Python script filters out any prod hub deployment job from running
      # later based on if its part of a cluster where support/staging upgrade
      # just failed. Data is injected to the script before its executed via
      # string literals as rendered GitHub workflow expressions.
      - name: Filter prod deploy jobs to run based on failures in support/staging
        id: filter-generate-jobs
        shell: python
        run: |
          import json

          jobs = json.loads(r"""${{ needs.generate-jobs.outputs.prod-hub-matrix-jobs }}""")
          outputs = json.loads(r"""${{ toJson(needs.upgrade-support-and-staging.outputs) }}""")

          filtered_jobs = [
              job
              for job in jobs
              if outputs[f"failure_{job['cluster_name'].replace('.', '-')}"] != "true"
          ]

          print(f"::set-output name=filtered-prod-hub-matrix-jobs::{json.dumps(filtered_jobs)}")

  # This job upgrades production hubs on clusters in parallel, if required. This
  # job needs both the `filter-generate-jobs` to have completed to provide its
  # output `filtered-prod-hub-matrix-jobs`. It is a list of dictionaries with
  # the keys cluster_name, provider, and hub_name for each production hub that
  # requires an upgrade and didn't have a failed support-and-staging-upgrade job
  # run as part of this workflow.
  upgrade-prod-hubs:
    runs-on: ubuntu-latest
    needs: [filter-generate-jobs]
    # Only run this job on pushes to the default branch and when the `generate-jobs` job output is not
    # an empty list
    #
    # always() is added as it seems to be a magic function to ensure a job can
    # run at all without being skipped if a previous job has had any failures.
    #
    if: |
      always() &&
      (github.event_name == 'push' && contains(github.ref, 'master')) &&
      needs.filter-generate-jobs.outputs.filtered-prod-hub-matrix-jobs != '[]'
    strategy:
      # Don't stop other deployments if one fails
      fail-fast: false
      matrix:
        jobs: ${{ fromJson(needs.filter-generate-jobs.outputs.filtered-prod-hub-matrix-jobs) }}

    steps:
      - name: Checkout repo
        uses: actions/checkout@v3

      - name: Setup deploy for ${{ matrix.jobs.cluster_name }} cluster
        uses: ./.github/actions/setup-deploy
        with:
          provider: ${{ matrix.jobs.provider }}
          GCP_KMS_DECRYPTOR_KEY: ${{ secrets.GCP_KMS_DECRYPTOR_KEY }}

      - name: Upgrade ${{ matrix.jobs.hub_name }} hub on cluster ${{ matrix.jobs.cluster_name }}
        run: |
          python deployer deploy ${{ matrix.jobs.cluster_name }} ${{ matrix.jobs.hub_name }}

      # Retry action: https://github.com/marketplace/actions/retry-step
      - name: Run health check against ${{ matrix.jobs.hub_name }} hub on cluster ${{ matrix.jobs.cluster_name}}
        uses: nick-fields/retry@v2.6.0
        with:
          timeout_minutes: 10
          max_attempts: 3
          command: |
            python deployer run-hub-health-check ${{ matrix.jobs.cluster_name }} ${{ matrix.jobs.hub_name }}
