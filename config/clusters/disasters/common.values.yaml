# nfs:
#   enabled: true
#   volumeReporter:
#     enabled: false
#   pv:
#     enabled: true
#     # from https://docs.aws.amazon.com/efs/latest/ug/mounting-fs-nfs-mount-settings.html
#     mountOptions:
#       - rsize=1048576
#       - wsize=1048576
#       - timeo=600
#       - soft # We pick soft over hard, so NFS lockups don't lead to hung processes
#       - retrans=2
#       - noresvport
#     baseShareName: /
dask-gateway:
  enabled: true
jupyterhub:
  custom:
    daskhubSetup:
      enabled: true
    2i2c:
      add_staff_user_ids_to_admin_users: true
      add_staff_user_ids_of_type: "github"
    jupyterhubConfigurator:
      enabled: false
    homepage:
      templateVars:
        org:
          name: "NASA Disasters Program"
          logo_url: https://github.com/NASA-IMPACT/veda-config-disasters/blob/221dbcee3ba0411eb6306008bb5f44714276ba28/overrides/components/header-brand/NASA_DISASTERS_LOGO_WHITE_TYPE-mapping-portal_small.png
          url: https://disasters-nasa.hub.arcgis.com/
        designed_by:
          name: "2i2c"
          url: https://2i2c.org
        operated_by:
          name: "2i2c"
          url: https://2i2c.org
        funded_by:
          name: "NASA"
          url: https://www.earthdata.nasa.gov/esds
  hub:
    allowNamedServers: true
    config:
      JupyterHub:
        authenticator_class: github
      GitHubOAuthenticator:
        populate_teams_in_auth_state: true
        # allowed_organizations:
        #   - todo
        scope:
          - read:org
      Authenticator:
        enable_auth_state: true
        admin_users:
          - freitagb
          - slesaad
  singleuser:
    cloudMetadata:
      blockWithIptables: false
    defaultUrl: /lab
    initContainers:
      - &volume_ownership_fix_initcontainer
        name: volume-mount-ownership-fix
        image: busybox:1.36.1
        command:
          - sh
          - -c
          - id && chown 1000:1000 /home/jovyan /home/jovyan/shared /home/jovyan/shared-public && ls -lhd /home/jovyan
        securityContext:
          runAsUser: 0
        volumeMounts:
          - name: home
            mountPath: /home/jovyan
            subPath: "{escaped_username}"
          # Mounted without readonly attribute here,
          # so we can chown it appropriately
          - name: home
            mountPath: /home/jovyan/shared
            subPath: _shared
          - name: home
            mountPath: /home/jovyan/shared-public
            subPath: _shared-public
    storage:
      extraVolumeMounts:
        - name: home
          mountPath: /home/jovyan/shared-public
          subPath: _shared-public
          readOnly: false
        - name: home
          mountPath: /home/rstudio/shared-public
          subPath: _shared-public
          readOnly: false
        - name: home
          mountPath: /home/jovyan/shared
          subPath: _shared
          readOnly: true
        - name: dev-shm
          mountPath: /dev/shm
    profileList:
      - display_name: Choose your environment and resources
        default: true
        profile_options:
          image:
            display_name: Environment
            dynamic_image_building:
              enabled: true
            unlisted_choice:
              enabled: True
              display_name: "Custom image"
              display_name_in_choices: "Bring your own image"
              validation_regex: "^.+:.+$"
              validation_message: "Must be a publicly available docker image, of form <image-name>:<tag>"
              kubespawner_override:
                image: "{value}"
            choices:
              01-modify-pangeo:
                display_name: Modified Pangeo Notebook
                description: Pangeo based notebook with a Python environment
                kubespawner_override:
                  image: public.ecr.aws/nasa-veda/pangeo-notebook-veda-image:2024.11.11-v1
                  init_containers:
                    # Need to explicitly fix ownership here, as otherwise these directories will be owned
                    # by root on most NFS filesystems - neither EFS nor Google Filestore support anonuid
                    - *volume_ownership_fix_initcontainer
                    # this container uses nbgitpuller to mount https://github.com/NASA-IMPACT/veda-docs/ for user pods
                    # image source: https://github.com/NASA-IMPACT/jupyterhub-gitpuller-init
                    - name: jupyterhub-gitpuller-init
                      image: public.ecr.aws/nasa-veda/jupyterhub-gitpuller-init:97eb45f9d23b128aff810e45911857d5cffd05c2
                      env:
                        - name: TARGET_PATH
                          value: veda-docs
                        - name: SOURCE_REPO
                          value: "https://github.com/NASA-IMPACT/veda-docs"
                      volumeMounts:
                        - name: home
                          mountPath: /home/jovyan
                          subPath: "{escaped_username}"
                      securityContext:
                        runAsUser: 1000
                        runAsGroup: 1000
              02-rocker:
                display_name: Rocker Geospatial with RStudio
                description: R environment with many geospatial libraries pre-installed
                kubespawner_override:
                  image: rocker/binder:4.4
                  image_pull_policy: Always
                  # Launch RStudio after the user logs in
                  default_url: /rstudio
                  # Ensures container working dir is homedir
                  # https://github.com/2i2c-org/infrastructure/issues/2559
                  working_dir: /home/rstudio
              03-qgis:
                display_name: QGIS on Linux Desktop
                description: Linux desktop in the browser, with qgis installed
                kubespawner_override:
                  # Launch people directly into the Linux desktop when they start
                  default_url: /desktop
                  # Built from https://github.com/2i2c-org/nasa-qgis-image
                  image: quay.io/2i2c/nasa-qgis-image:607df3f5c661
          resource_allocation:
            display_name: Resource Allocation
            choices:
              mem_1_9:
                display_name: 1.9 GB RAM, upto 3.7 CPUs
                kubespawner_override:
                  mem_guarantee: 1991244775
                  mem_limit: 1991244775
                  cpu_guarantee: 0.2328125
                  cpu_limit: 3.725
                  node_selector:
                    node.kubernetes.io/instance-type: r5.xlarge
                default: true
              mem_3_7:
                display_name: 3.7 GB RAM, upto 3.7 CPUs
                kubespawner_override:
                  mem_guarantee: 3982489550
                  mem_limit: 3982489550
                  cpu_guarantee: 0.465625
                  cpu_limit: 3.725
                  node_selector:
                    node.kubernetes.io/instance-type: r5.xlarge
              mem_7_4:
                display_name: 7.4 GB RAM, upto 3.7 CPUs
                kubespawner_override:
                  mem_guarantee: 7964979101
                  mem_limit: 7964979101
                  cpu_guarantee: 0.93125
                  cpu_limit: 3.725
                  node_selector:
                    node.kubernetes.io/instance-type: r5.xlarge
              mem_14_8:
                display_name: 14.8 GB RAM, upto 3.7 CPUs
                kubespawner_override:
                  mem_guarantee: 15929958203
                  mem_limit: 15929958203
                  cpu_guarantee: 1.8625
                  cpu_limit: 3.725
                  node_selector:
                    node.kubernetes.io/instance-type: r5.xlarge
              mem_29_7:
                display_name: 29.7 GB RAM, upto 3.7 CPUs
                kubespawner_override:
                  mem_guarantee: 31859916406
                  mem_limit: 31859916406
                  cpu_guarantee: 3.725
                  cpu_limit: 3.725
                  node_selector:
                    node.kubernetes.io/instance-type: r5.xlarge
              mem_60_6:
                display_name: 60.6 GB RAM, upto 15.6 CPUs
                kubespawner_override:
                  mem_guarantee: 65094448840
                  mem_limit: 65094448840
                  cpu_guarantee: 7.8475
                  cpu_limit: 15.695
                  node_selector:
                    node.kubernetes.io/instance-type: r5.4xlarge
              mem_121_2:
                display_name: 121.2 GB RAM, upto 15.6 CPUs
                kubespawner_override:
                  mem_guarantee: 130188897681
                  mem_limit: 130188897681
                  cpu_guarantee: 15.695
                  cpu_limit: 15.695
                  node_selector:
                    node.kubernetes.io/instance-type: r5.4xlarge
      - display_name: NVIDIA Tesla T4, ~16 GB, ~4 CPUs
        description: "Start a container on a dedicated node with a GPU"
        slug: "gpu"
        allowed_groups:
          - 2i2c-org:hub-access-for-2i2c-staff
        profile_options:
          image:
            display_name: Environment
            dynamic_image_building:
              enabled: true
            unlisted_choice:
              enabled: true
              display_name: "Custom image"
              validation_regex: "^.+:.+$"
              validation_message: "Must be a publicly available docker image of form <image-name>:<tag>"
              kubespawner_override:
                image: "{value}"
            choices:
              pytorch:
                display_name: Pangeo PyTorch ML Notebook
                default: false
                slug: "pytorch"
                kubespawner_override:
                  image: "quay.io/pangeo/pytorch-notebook:2024.11.11"
              tensorflow2:
                display_name: Pangeo Tensorflow2 ML Notebook
                default: true
                slug: "tensorflow2"
                kubespawner_override:
                  image: "quay.io/pangeo/ml-notebook:2024.11.11"
        kubespawner_override:
          environment:
            NVIDIA_DRIVER_CAPABILITIES: compute,utility
          mem_limit: null
          mem_guarantee: 14G
          node_selector:
            node.kubernetes.io/instance-type: g4dn.xlarge
          extra_resource_limits:
            nvidia.com/gpu: "1"

  scheduling:
    userScheduler:
      enabled: true

binderhub-service:
  enabled: true
  # Explicitly specify what nodes we want for our builds
  # Otherwise we may scale up a larger node than neededx
  dockerApi:
    nodeSelector:
      node.kubernetes.io/instance-type: r5.xlarge
  config:
    KubernetesBuildExecutor:
      node_selector:
        node.kubernetes.io/instance-type: r5.xlarge
    DockerRegistry:
      url: &url https://quay.io
      username: &username imagebuilding-non-gcp-hubs+image_builder
  buildPodsRegistryCredentials:
    server: *url
    username: *username

jupyterhub-home-nfs:
  enabled: true
  eks:
    enabled: true
  prometheusExporter:
    enabled: true
