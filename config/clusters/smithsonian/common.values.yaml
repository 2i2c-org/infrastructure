basehub:
  nfs:
    pv:
      # from https://docs.aws.amazon.com/efs/latest/ug/mounting-fs-nfs-mount-settings.html
      mountOptions:
        - rsize=1048576
        - wsize=1048576
        - timeo=600
        - soft # We pick soft over hard, so NFS lockups don't lead to hung processes
        - retrans=2
        - noresvport
      serverIP: fs-0ba20c6122f4a7236.efs.us-east-2.amazonaws.com
      baseShareName: /

  jupyterhub:
    custom:
      2i2c:
        add_staff_user_ids_to_admin_users: true
        add_staff_user_ids_of_type: "github"
      homepage:
        templateVars:
          org:
            name: Smithsonian
            logo_url: https://logo.si.edu/wp-content/uploads/2018/07/logo_primary.svg
            url: https://www.si.edu/
          designed_by:
            name: 2i2c
            url: https://2i2c.org
          operated_by:
            name: 2i2c
            url: https://2i2c.org
          funded_by:
            name: Smithsonian
            url: https://www.si.edu/

    hub:
      config:
        JupyterHub:
          authenticator_class: github
        GitHubOAuthenticator:
          populate_teams_in_auth_state: true
          allowed_organizations: &allowed_github_orgs
            - 2i2c-org
            - smithsonian
            - sidatasciencelab
            - Smithsonian-SDCH
          scope:
            - read:org
        Authenticator:
          enable_auth_state: true
          admin_users:
            - MikeTrizna # Mike Trizna
            - rdikow # Rebecca Dikow
            - aewhite100 # Alex White

    scheduling:
      userScheduler:
        enabled: true

    singleuser:
      profileList:
        # NOTE: About node sharing
        #
        #       CPU/Memory requests/limits are actively considered still. This
        #       profile list is setup to involve node sharing as considered in
        #       https://github.com/2i2c-org/infrastructure/issues/2121.
        #
        #       - Memory requests are different from the description, based on:
        #         whats found to remain allocate in k8s, subtracting 1GiB
        #         overhead for misc system pods, and transitioning from GB in
        #         description to GiB in mem_guarantee.
        #       - CPU requests are lower than the description, with a factor of
        #         10%.
        #
        - display_name: "Small: up to 4 CPU / 32 GB RAM"
          description: &profile_list_description "Start a container with at least a chosen share of capacity on a node of this type"
          slug: small
          default: true
          allowed_teams: *allowed_github_orgs
          profile_options:
            image: &profile_options_image
              display_name: Image
              choices:
                geospatial:
                  display_name: Rocker Geospatial
                  default: true
                  slug: geospatial
                  kubespawner_override:
                    image: rocker/binder:4.3
                    working_dir: /home/rstudio
                    default_url: /rstudio
                    volume_mounts:
                      - name: home
                        mountPath: /home/rstudio
                        subPath: "{username}"
                      - name: home
                        mountPath: /home/rstudio/shared
                        subPath: _shared
                        readOnly: true
                scipy:
                  display_name: Jupyter SciPy Notebook
                  slug: scipy
                  kubespawner_override:
                    image: "jupyter/scipy-notebook:2023-09-04"
                pangeo:
                  display_name: Pangeo Notebook
                  slug: pangeo
                  kubespawner_override:
                    image: "quay.io/pangeo/pangeo-notebook:2023.08.29"
                tensorflow: &image_tensorflow
                  display_name: Pangeo Tensorflow ML Notebook
                  slug: tensorflow
                  kubespawner_override:
                    image: "pangeo/ml-notebook:2023.08.29"
                pytorch: &image_pytorch
                  display_name: Pangeo PyTorch ML Notebook
                  slug: pytorch
                  kubespawner_override:
                    image: "pangeo/pytorch-notebook:2023.08.29"
            requests:
              # NOTE: Node share choices are in active development, see comment
              #       next to profileList: above.
              display_name: Node share
              choices:
                mem_1:
                  default: true
                  display_name: ~1 GB, ~0.125 CPU
                  kubespawner_override:
                    mem_guarantee: 0.904G
                    cpu_guarantee: 0.013
                mem_2:
                  display_name: ~2 GB, ~0.25 CPU
                  kubespawner_override:
                    mem_guarantee: 1.809G
                    cpu_guarantee: 0.025
                mem_4:
                  display_name: ~4 GB, ~0.5 CPU
                  kubespawner_override:
                    mem_guarantee: 3.617G
                    cpu_guarantee: 0.05
                mem_8:
                  display_name: ~8 GB, ~1.0 CPU
                  kubespawner_override:
                    mem_guarantee: 7.234G
                    cpu_guarantee: 0.1
                mem_16:
                  display_name: ~16 GB, ~2.0 CPU
                  kubespawner_override:
                    mem_guarantee: 14.469G
                    cpu_guarantee: 0.2
                mem_32:
                  display_name: ~32 GB, ~4.0 CPU
                  kubespawner_override:
                    mem_guarantee: 28.937G
                    cpu_guarantee: 0.4
          kubespawner_override:
            cpu_limit: null
            mem_limit: null
            node_selector:
              node.kubernetes.io/instance-type: r5.xlarge

        - display_name: NVIDIA Tesla T4, ~16 GB, ~4 CPUs
          slug: gpu
          description: "Start a container on a dedicated node with a GPU"
          allowed_teams:
            - 2i2c-org:hub-access-for-2i2c-staff
            - Smithsonian-SDCH:gpu-users
          profile_options:
            image:
              display_name: Image
              choices:
                tensorflow: *image_tensorflow
                pytorch: *image_pytorch
          kubespawner_override:
            mem_limit: null
            environment:
              NVIDIA_DRIVER_CAPABILITIES: compute,utility
            mem_guarantee: 14G
            node_selector:
              node.kubernetes.io/instance-type: g4dn.xlarge
            extra_resource_limits:
              nvidia.com/gpu: "1"
