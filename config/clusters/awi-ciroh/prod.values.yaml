basehub:
  nfs:
    pv:
      serverIP: 10.99.243.170
  userServiceAccount:
    annotations:
      iam.gke.io/gcp-service-account: awi-ciroh-prod@ciroh-jupyterhub-423218.iam.gserviceaccount.com
  jupyterhub-home-nfs:
    gke:
      volumeId: projects/ciroh-jupyterhub-423218/zones/us-central1-b/disks/hub-nfs-homedirs-prod
    quotaEnforcer:
      hardQuota: "250" # in GB
      path: "/export/prod"
  jupyterhub:
    ingress:
      hosts: [ciroh.awi.2i2c.cloud]
      tls:
        - hosts: [ciroh.awi.2i2c.cloud]
          secretName: https-auto-tls
    singleuser:
      profileList:
        # The mem-guarantees are here so k8s doesn't schedule other pods
        # on these nodes. They need to be just under total allocatable
        # RAM on a node, not total node capacity. Values calculated using
        # https://learnk8s.io/kubernetes-instance-calculator
        #
        # FIXME: These are changed to a temporary node sharing setup based on
        #        the legacy choices to help us pre-warm capacity independent on
        #        the choices users end up making and avoiding running into
        #        persistent disk quotas.
        #
        #        Change PR: https://github.com/2i2c-org/infrastructure/pull/2539
        #        Related event: https://github.com/2i2c-org/infrastructure/issues/2520
        #
        #        This is an interim setup, trying to balance the experience of
        #        the previous 1:1 user:node setup with a node sharing setup. It
        #        is not meant to be retained long term!
        #
        #        -[ ] Make this cluster have a node sharing setup like in the
        #             basehub/daskhub template.
        #
        - display_name: "Small"
          description: 5GB RAM, 2 CPUs
          default: true
          profile_options: &profile_options
            image:
              display_name: Image
              # Requested in https://2i2c.freshdesk.com/a/tickets/1387
              choices:
                old:
                  display_name: Original Pangeo Notebook base image 2023.09.11
                  slug: "old"
                  kubespawner_override:
                    image: "quay.io/2i2c/awi-ciroh-image:d9f753c83a6b"
                new:
                  display_name: New Pangeo Notebook base image 2024.04.08
                  default: true
                  slug: "new"
                  kubespawner_override:
                    image: "quay.io/2i2c/awi-ciroh-image:43afa7f902b4"
                rkernel:
                  display_name: Notebook with R and Python kernel
                  slug: "rkernel"
                  kubespawner_override:
                    image: "quay.io/2i2c/awi-ciroh-image:f7f6aa41555b"
                preprocessor:
                  display_name: "NGIAB Data Preprocessor"
                  kubespawner_override:
                    # From  https://github.com/CIROH-UA/NGIAB_data_preprocess
                    image: "quay.io/awiciroh/devcon25:ngiab_datapreprocess"
                    image_pull_policy: "Always"
          kubespawner_override:
            mem_limit: 7G
            mem_guarantee: 5G
            cpu_limit: 2
            cpu_guarantee: 0.938
            node_selector:
              node.kubernetes.io/instance-type: n2-highmem-16
        - display_name: Medium
          description: 11GB RAM, 4 CPUs
          profile_options: *profile_options
          kubespawner_override:
            mem_limit: 15G
            mem_guarantee: 11G
            cpu_limit: 4
            cpu_guarantee: 1.875
            node_selector:
              node.kubernetes.io/instance-type: n2-highmem-16
        - display_name: Large
          description: 24GB RAM, 8 CPUs
          profile_options: *profile_options
          kubespawner_override:
            mem_limit: 30G
            mem_guarantee: 24G
            cpu_limit: 8
            cpu_guarantee: 3.75
            node_selector:
              node.kubernetes.io/instance-type: n2-highmem-16
        - display_name: Huge
          description: 52GB RAM, 16 CPUs
          profile_options: *profile_options
          kubespawner_override:
            mem_limit: 60G
            mem_guarantee: 52G
            cpu_limit: 16
            cpu_guarantee: 7.5
            node_selector:
              node.kubernetes.io/instance-type: n2-highmem-16
        - display_name: NVIDIA Tesla T4, ~16 GB, ~4 CPUs
          description: "Start a container on a dedicated node with a GPU"
          allowed_groups:
            - 2i2c-org:hub-access-for-2i2c-staff
            - AlabamaWaterInstitute:2i2c_portal_users_gpu
          profile_options:
            image:
              display_name: Image
              choices:
                tensorflow:
                  display_name: Pangeo Tensorflow ML Notebook
                  slug: "tensorflow"
                  kubespawner_override:
                    image: "pangeo/ml-notebook:2024.05.07"
                pytorch:
                  display_name: Pangeo PyTorch ML Notebook
                  default: true
                  slug: "pytorch"
                  kubespawner_override:
                    image: "pangeo/pytorch-notebook:2024.05.07"
          kubespawner_override:
            environment:
              NVIDIA_DRIVER_CAPABILITIES: compute,utility
            mem_limit: null
            mem_guarantee: 14G
            node_selector:
              node.kubernetes.io/instance-type: n1-highmem-8
            extra_resource_limits:
              nvidia.com/gpu: "1"
      extraEnv:
        SCRATCH_BUCKET: gs://awi-ciroh-scratch/$(JUPYTERHUB_USER)
        PANGEO_SCRATCH: gs://awi-ciroh-scratch/$(JUPYTERHUB_USER)
        PERSISTENT_BUCKET: gs://awi-ciroh-persistent/$(JUPYTERHUB_USER)
    hub:
      config:
        GitHubOAuthenticator:
          oauth_callback_url: "https://ciroh.awi.2i2c.cloud/hub/oauth_callback"
