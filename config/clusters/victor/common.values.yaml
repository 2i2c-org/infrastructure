basehub:
  nfs:
    enabled: true
    volumeReporter:
      enabled: false
    pv:
      enabled: true
      # from https://docs.aws.amazon.com/efs/latest/ug/mounting-fs-nfs-mount-settings.html
      mountOptions:
        - rsize=1048576
        - wsize=1048576
        - timeo=600
        - soft # We pick soft over hard, so NFS lockups don't lead to hung processes
        - retrans=2
        - noresvport
      serverIP: fs-00c0183a99b47c9ed.efs.us-west-2.amazonaws.com
      baseShareName: /
  jupyterhub:
    custom:
      2i2c:
        add_staff_user_ids_to_admin_users: true
        add_staff_user_ids_of_type: "github"
      homepage:
        gitRepoBranch: "victor"
        templateVars:
          org:
            name: VICTOR
            logo_url: https://i.imgur.com/D2vXQ5k.png
            url: https://victor.ldeo.columbia.edu
          designed_by:
            name: 2i2c
            url: https://2i2c.org
          operated_by:
            name: 2i2c
            url: https://2i2c.org
          funded_by:
            name: "National Science Foundation"
            url: https://people.climate.columbia.edu/projects/sponsor/National%20Science%20Foundation
    hub:
      config:
        JupyterHub:
          authenticator_class: github
        GitHubOAuthenticator:
          allowed_organizations:
            - VICTOR-Community:victoraccess
          scope:
            - read:org
        Authenticator:
          admin_users:
            - einatlev-ldeo
            - SamKrasnoff
    singleuser:
      profileList:
        # The mem-guarantees are here so k8s doesn't schedule other pods
        # on these nodes.
        - display_name: "Small: m5.large"
          description: "~2 CPU, ~8G RAM"
          default: true
          kubespawner_override:
            # Explicitly unset mem_limit, so it overrides the default memory limit we set in
            # basehub/values.yaml
            mem_limit: 8G
            mem_guarantee: 6.5G
            node_selector:
              node.kubernetes.io/instance-type: m5.large
          profile_options: &profile_options
            image:
              display_name: Image
              choices:
                a-victor-notebook:
                  display_name: Victor Notebook
                  default: true
                  kubespawner_override:
                    image: quay.io/volcanocyber/victor-notebook:a045ad3616d1
                b-pytorch-notebook:
                  display_name: Pangeo ML Notebook (Pytorch)
                  kubespawner_override:
                    image: "quay.io/pangeo/pytorch-notebook:2024.09.11"
                c-ml-notebook:
                  display_name: Pangeo ML Notebook (Tensorflow)
                  kubespawner_override:
                    image: "quay.io/pangeo/ml-notebook:2024.09.11"
        - display_name: "Medium: m5.xlarge"
          description: "~4 CPU, ~15G RAM"
          kubespawner_override:
            mem_limit: 15G
            mem_guarantee: 12G
            node_selector:
              node.kubernetes.io/instance-type: m5.xlarge
          profile_options: *profile_options
        - display_name: "Large: m5.2xlarge"
          description: "~8 CPU, ~30G RAM"
          kubespawner_override:
            mem_limit: 30G
            mem_guarantee: 25G
            node_selector:
              node.kubernetes.io/instance-type: m5.2xlarge
          profile_options: *profile_options
        - display_name: "Huge: m5.8xlarge"
          description: "~16 CPU, ~60G RAM"
          kubespawner_override:
            mem_limit: 60G
            mem_guarantee: 50G
            node_selector:
              node.kubernetes.io/instance-type: m5.8xlarge
          profile_options: *profile_options
        - display_name: NVIDIA Tesla T4, ~16 GB, ~4 CPUs
          description: "Start a container on a dedicated node with a GPU"
          slug: "gpu"
          kubespawner_override:
            environment:
              NVIDIA_DRIVER_CAPABILITIES: compute,utility
            mem_limit: null
            mem_guarantee: 14G
            node_selector:
              node.kubernetes.io/instance-type: g4dn.xlarge
            extra_resource_limits:
              nvidia.com/gpu: "1"
          profile_options: *profile_options
      defaultUrl: /lab
    scheduling:
      userScheduler:
        enabled: true
