basehub:
  nfs:
    pv:
      serverIP: 10.100.14.113
  userServiceAccount:
    annotations:
      eks.amazonaws.com/role-arn: arn:aws:iam::129856558350:role/victor-prod
  dask-gateway:
    gateway:
      backend:
        scheduler:
          extraPodConfig:
            nodeSelector:
              2i2c/hub-name: prod
        worker:
          extraPodConfig:
            nodeSelector:
              2i2c/hub-name: prod
  jupyterhub-home-nfs:
    eks:
      volumeId: vol-0aa2e34864c248eb2
    quotaEnforcer:
      config:
        QuotaManager:
          hard_quota: 20 # in GiB
  jupyterhub:
    ingress:
      hosts: [hub.victorproject.org]
      tls:
      - hosts: [hub.victorproject.org]
        secretName: https-auto-tls
    hub:
      config:
        CILogonOAuthenticator:
          oauth_callback_url: https://hub.victorproject.org/hub/oauth_callback
    singleuser:
      nodeSelector:
        2i2c/hub-name: prod
      profileList:
        # IMPORTANT: Staging and prod's profileList's are meant to be kept
        #            equivalent with the exception that staging adds
        #            unlisted_choice to pick a custom image. If you update
        #            either, update the other as well.
        #
      - display_name: CPU Only
        profile_options:
          image: &profile_option_image
            display_name: Image
            choices:
              a-victor-notebook:
                display_name: Victor Notebook
                default: true
                kubespawner_override:
                  image: quay.io/volcanocyber/victor-notebook:343c0be363bb
              b-pytorch-notebook:
                display_name: Pangeo ML Notebook (Pytorch)
                kubespawner_override:
                  image: quay.io/pangeo/pytorch-notebook:2024.09.11
              c-ml-notebook:
                display_name: Pangeo ML Notebook (Tensorflow)
                kubespawner_override:
                  image: quay.io/pangeo/ml-notebook:2024.09.11
          resource_allocation:
            display_name: Resource Allocation
            choices:
                # r5.xlarge
                # [[[cog
                # from deployer.dev_commands.generate.resource_allocation.generate_choices import choices
                # choices(["r5.xlarge:4"], "proportional-memory-strategy", default=True)
                # ]]]
                # [[[end]]]

                # r5.4xlarge
                # [[[cog
                # from deployer.dev_commands.generate.resource_allocation.generate_choices import choices
                # choices(["r5.4xlarge:2"], "proportional-memory-strategy")
                # ]]]
                # [[[end]]]
      - display_name: NVIDIA Tesla T4, ~16 GB, ~4 CPUs
        description: Start a container on a dedicated node with a GPU
        slug: gpu
        kubespawner_override:
          environment:
            NVIDIA_DRIVER_CAPABILITIES: compute,utility
          mem_limit:
          mem_guarantee: 14G
          node_selector:
            node.kubernetes.io/instance-type: g4dn.xlarge
          extra_resource_limits:
            nvidia.com/gpu: '1'
        profile_options:
          image: *profile_option_image
