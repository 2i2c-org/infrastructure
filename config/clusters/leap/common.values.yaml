basehub:
  nfs:
    enabled: true
    pv:
      mountOptions:
        - soft
        - noatime
      # Google FileStore IP
      serverIP: 10.104.103.242
      # Name of Google Filestore share
      baseShareName: /homes/
  jupyterhub:
    proxy:
      https:
        enabled: false
    custom:
      2i2c:
        add_staff_user_ids_to_admin_users: true
        add_staff_user_ids_of_type: "github"
      homepage:
        templateVars:
          org:
            name: LEAP
            url: https://leap-stc.github.io
            logo_url: https://leap-stc.github.io/_static/LEAP_logo.png
          designed_by:
            name: 2i2c
            url: https://2i2c.org
          operated_by:
            name: 2i2c
            url: https://2i2c.org
          funded_by:
            name: LEAP
            url: https://leap-stc.github.io
    hub:
      allowNamedServers: true
      config:
        Authenticator:
          enable_auth_state: true
          # This hub uses GitHub Teams auth and so we don't set
          # allowed_users in order to not deny access to valid members of
          # the listed teams. These people should have admin access though.
          admin_users:
            - rabernat
        JupyterHub:
          authenticator_class: github
        GitHubOAuthenticator:
          populate_teams_in_auth_state: true
          allowed_organizations:
            - leap-stc:leap-pangeo-users
            - 2i2c-org:tech-team
          scope:
            - read:org
    singleuser:
      image:
        name: pangeo/pangeo-notebook
        tag: "2022.10.13"
      extraEnv:
        GH_SCOPED_CREDS_CLIENT_ID: "Iv1.0c7df3d4b3191b2f"
        GH_SCOPED_CREDS_APP_URL: https://github.com/apps/leap-hub-push-access
        # Temporarily set for *all* pods, including pods without any GPUs,
        # to work around https://github.com/2i2c-org/infrastructure/issues/1530
        NVIDIA_DRIVER_CAPABILITIES: compute,utility
      profileList:
        # The mem-guarantees are here so k8s doesn't schedule other pods
        # on these nodes. They need to be just under total allocatable
        # RAM on a node, not total node capacity. Values calculated using
        # https://learnk8s.io/kubernetes-instance-calculator
        - display_name: "Small"
          description: 5GB RAM, 2 CPUs
          default: true
          allowed_teams:
            - leap-stc:leap-pangeo-users
            - 2i2c-org:tech-team
          kubespawner_override:
            mem_limit: 7G
            mem_guarantee: 4.5G
            node_selector:
              node.kubernetes.io/instance-type: n1-standard-2
        - display_name: Medium
          description: 11GB RAM, 4 CPUs
          allowed_teams:
            - leap-stc:leap-pangeo-users
            - 2i2c-org:tech-team
          kubespawner_override:
            mem_limit: 15G
            mem_guarantee: 11G
            node_selector:
              node.kubernetes.io/instance-type: n1-standard-4
        - display_name: Large
          description: 24GB RAM, 8 CPUs
          allowed_teams:
            - leap-stc:leap-pangeo-education
            - leap-stc:leap-pangeo-research
            - 2i2c-org:tech-team
          kubespawner_override:
            mem_limit: 30G
            mem_guarantee: 24G
            node_selector:
              node.kubernetes.io/instance-type: n1-standard-8
        - display_name: Huge
          description: 52GB RAM, 16 CPUs
          allowed_teams:
            - leap-stc:leap-pangeo-research
            - 2i2c-org:tech-team
          kubespawner_override:
            mem_limit: 60G
            mem_guarantee: 52G
            node_selector:
              node.kubernetes.io/instance-type: n1-standard-16

        - display_name: Large + GPU
          description: 24GB RAM, 8 CPUs
          allowed_teams:
            - leap-stc:leap-pangeo-research
            - 2i2c-org:tech-team
          profile_options:
            gpu:
              display_name: GPU
              choices:
                k80:
                  display_name: NVidia Tesla K80
                  slug: k80
                  kubespawner_override:
                    node_selector:
                      node.kubernetes.io/instance-type: n1-standard-8
                      cloud.google.com/gke-nodepool: nb-gpu-k80
                t4:
                  display_name: NVidia Tesla T4
                  slug: t4
                  default: true
                  kubespawner_override:
                    node_selector:
                      node.kubernetes.io/instance-type: n1-standard-8
                      cloud.google.com/gke-nodepool: nb-gpu-t4
            image:
              display_name: Image
              choices:
                tensorflow:
                  display_name: Pangeo Tensorflow ML Notebook
                  default: true
                  slug: "tensorflow"
                  kubespawner_override:
                    image: "pangeo/ml-notebook:2022.10.13"
                pytorch:
                  display_name: Pangeo PyTorch ML Notebook
                  slug: "pytorch"
                  kubespawner_override:
                    image: "pangeo/pytorch-notebook:2022.10.13"
          kubespawner_override:
            mem_limit: 30G
            mem_guarantee: 24G
            extra_resource_limits:
              nvidia.com/gpu: "1"
dask-gateway:
  gateway:
    backend:
      scheduler:
        cores:
          request: 1
          limit: 2
        memory:
          request: 4G
          limit: 4G
