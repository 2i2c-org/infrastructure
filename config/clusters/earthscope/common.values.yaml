basehub:
  nfs:
    enabled: true
    volumeReporter:
      enabled: false
    pv:
      enabled: true
      # from https://docs.aws.amazon.com/efs/latest/ug/mounting-fs-nfs-mount-settings.html
      mountOptions:
      - rsize=1048576
      - wsize=1048576
      - timeo=600
      - soft   # We pick soft over hard, so NFS lockups don't lead to hung processes
      - retrans=2
      - noresvport
      serverIP: fs-08e7747330d833d82.efs.us-east-2.amazonaws.com
  dask-gateway:
    enabled: true
  jupyterhub:
    custom:
      daskhubSetup:
        enabled: true
      2i2c:
        # This uses custom ids from auth0, so we can't use our default
        # emails as access
        add_staff_user_ids_to_admin_users: false
    hub:
      extraConfig:
        001-username-claim: |
          import json
          from oauthenticator.generic import GenericOAuthenticator
          from traitlets import List, Unicode
          from urllib.parse import urlparse

          class CustomGenericOAuthenticator(GenericOAuthenticator):
            # required_scopes functionality comes in from https://github.com/jupyterhub/oauthenticator/pull/719
            # Can be removed from here once that PR is merged
            required_scopes = List(
                Unicode(),
                config=True,
                help="""
                List of scopes that must be granted to allow login.

                All the scopes listed in this config must be present in the OAuth2 grant
                from the authorizing server to allow the user to login. We request all
                the scopes listed in the 'scope' config, but only a subset of these may
                be granted by the authorization server. This may happen if the user does not
                have permissions to access a requested scope, or has chosen to not give consent
                for a particular scope. If the scopes listed in this config are not granted,
                the user will not be allowed to log in.

                See the OAuth documentation of your OAuth provider for various options.
                """,
            )

            async def check_allowed(self, username, auth_model):
              if await super().check_allowed(username, auth_model):
                  return True

              if self.required_scopes:
                  granted_scopes = auth_model.get('auth_state', {}).get('scope', [])
                  missing_scopes = set(self.required_scopes) - set(granted_scopes)
                  if missing_scopes:
                      self.log.info(f"Denying access to user {username} - scopes {missing_scopes} were not granted, only {granted_scopes} were granted")
                      return False
                  else:
                      return True

              return False

            async def authenticate(self, *args, **kwargs):
              resp = await super().authenticate(*args, **kwargs)
              # Setup groups to be same as list of scopes granted
              # This can go away after https://github.com/jupyterhub/oauthenticator/pull/735 is
              # merged
              resp["groups"] = resp["auth_state"]["scope"]
              return resp

          def populate_token(spawner, auth_state):
            # For our deployment-service-check health check user, there is no auth_state.
            # So these env variables need not be set.
            if auth_state:
              url_parts = urlparse(spawner.authenticator.token_url)
              base_url = f"{url_parts.scheme}://{url_parts.netloc}"
              scope_str = " ".join(spawner.authenticator.scope)

              # Bootstrap EarthScope SDK settings
              settings = {
                "oauth2": {
                  "audience": spawner.authenticator.extra_authorize_params.get("audience", ""),
                  "client_id": spawner.authenticator.client_id,
                  "domain": base_url,
                  "scope": scope_str,
                  "access_token": auth_state.get("access_token", ""),
                  "id_token": auth_state.get("id_token", ""),
                  "refresh_token": auth_state.get("refresh_token", "")
                }
              }

              # The spawner expands environment variables using string.format, so we need to escape braces.
              settings_str = json.dumps(settings)
              escaped_settings_str = settings_str.replace("{", "{{").replace("}", "}}")

              spawner.environment.update({
                "ES_BOOTSTRAP_SETTINGS": escaped_settings_str
              })

          c.Spawner.auth_state_hook = populate_token

          c.JupyterHub.authenticator_class = CustomGenericOAuthenticator
      config:
        CustomGenericOAuthenticator:
          required_scopes:
            # This allows EarthScope to control who can login to the hub
          - geolab
        GenericOAuthenticator:
          scope:
          - openid
            # This gives us refresh token
          - offline_access
            # This allows EarthScope to control who can login to the hub
            # Everyone who logs in with Google and has a `@2i2c.org` email will be
            # automatically granted this scope, so we can test. See
            # https://2i2c.freshdesk.com/a/tickets/1280 for how this was granted.
          - geolab
          - geolab:dev
          - geolab:power
          extra_authorize_params:
            # This isn't an actual URL, just a string. Must not have a trailing slash
            audience: https://api.dev.earthscope.org
          username_claim: sub
          # Convert 'scope' from the OAuth2 response into JupyterHub groups
          manage_groups: true
        CILogonOAuthenticator:
          allowed_idps:
            http://github.com/login/oauth/authorize:
              default: true
              username_derivation:
                username_claim: preferred_username
            http://google.com/accounts/o8/id:
              username_derivation:
                username_claim: email
        Authenticator:
          enable_auth_state: true
          admin_users:
          - google-oauth2|117718799995701713253   #Chad Trabant, https://2i2c.freshdesk.com/a/tickets/1279
          - google-oauth2|117710759588624106233   #Sarah Wilson
          - google-oauth2|112630227497477971771   #Robert Weekly
          - google-oauth2|118403506154942842583   #Alex Hamilton
          - google-oauth2|108516754518362587599   # Yuvi
          - google-oauth2|117859169473992122769   # Georgiana
          - google-oauth2|117322480787655244438   # Jenny
    singleuser:
      cloudMetadata:
        blockWithIptables: false
      profileList:
      - display_name: Choose your environment and resources
        default: true
        profile_options:
          image:
            display_name: Environment
            unlisted_choice:
              enabled: true
              display_name: Custom image
              validation_regex: ^.+:.+$
              validation_message: Must be a publicly available docker image, of form <image-name>:<tag>
              kubespawner_override:
                image: '{value}'
            dynamic_image_building:
              enabled: true
            choices:
              geolab-general:
                display_name: GeoLab
                slug: geolab-general
                kubespawner_override:
                  image: public.ecr.aws/earthscope/geolab/geolab-default:latest
              mspass-shortcourse:
                display_name: MsPASS ShortCourse
                slug: mspass-shortcourse
                kubespawner_override:
                  image: public.ecr.aws/earthscope-dev/mspass_image:mspass_img_test-6db62782
              jupyter-scipy:
                display_name: Jupyter
                slug: jupyter-scipy
                kubespawner_override:
                    # FIXME: use quay.io/ for tags after 2023-10-20
                  image: jupyter/scipy-notebook:2023-06-27
              rocker-geospatial:
                display_name: RStudio
                slug: rocker-geospatial
                kubespawner_override:
                  image: rocker/binder:4.3
                  image_pull_policy: Always
                    # Launch into RStudio after the user logs in
                  default_url: /rstudio
                    # Ensures container working dir is homedir
                    # https://github.com/2i2c-org/infrastructure/issues/2559
                  working_dir: /home/rstudio
          resource_allocation:
            display_name: Resource Allocation
            choices:
              mem_4_gb:
                display_name: 4 GB RAM, ~0.5 CPUs
                description: Upto ~4 CPUs when available
                allowed_groups:
                - geolab
                - geolab:dev
                - geolab:power
                kubespawner_override:
                  mem_guarantee: 3902839759
                  mem_limit: 3902839759
                  cpu_guarantee: 0.4563125
                  cpu_limit: 3.6505
                  node_selector:
                    node.kubernetes.io/instance-type: r5.xlarge
              mem_7_gb:
                display_name: 7 GB RAM, ~0.9 CPUs
                description: Upto ~4 CPUs when available
                allowed_groups:
                - geolab
                - geolab:dev
                - geolab:power
                kubespawner_override:
                  mem_guarantee: 7805679519
                  mem_limit: 7805679519
                  cpu_guarantee: 0.912625
                  cpu_limit: 3.6505
                  node_selector:
                    node.kubernetes.io/instance-type: r5.xlarge
              mem_15_gb:
                display_name: 15 GB RAM, ~1.8 CPUs
                description: Upto ~4 CPUs when available
                allowed_groups:
                - geolab
                - geolab:dev
                - geolab:power
                kubespawner_override:
                  mem_guarantee: 15611359038
                  mem_limit: 15611359038
                  cpu_guarantee: 1.82525
                  cpu_limit: 3.6505
                  node_selector:
                    node.kubernetes.io/instance-type: r5.xlarge
              mem_29_gb:
                display_name: 29 GB RAM, ~4 CPUs
                description: ~4 CPUs always available
                allowed_groups:
                - geolab
                - geolab:dev
                - geolab:power
                kubespawner_override:
                  mem_guarantee: 31222718077
                  mem_limit: 31222718077
                  cpu_guarantee: 3.6505
                  cpu_limit: 3.6505
                  node_selector:
                    node.kubernetes.io/instance-type: r5.xlarge
              mem_60_gb:
                display_name: 60 GB RAM, ~8 CPUs
                description: Upto ~15 CPUs when available
                allowed_groups:
                - geolab:dev
                - geolab:power
                kubespawner_override:
                  mem_guarantee: 64020707016
                  mem_limit: 64020707016
                  cpu_guarantee: 7.69055
                  cpu_limit: 15.3811
                  node_selector:
                    node.kubernetes.io/instance-type: r5.4xlarge
              mem_119_gb:
                display_name: 119 GB RAM, ~15 CPUs
                description: ~15 CPUs always available
                allowed_groups:
                - geolab:dev
                - geolab:power
                kubespawner_override:
                  mem_guarantee: 128041414033
                  mem_limit: 128041414033
                  cpu_guarantee: 15.3811
                  cpu_limit: 15.3811
                  node_selector:
                    node.kubernetes.io/instance-type: r5.4xlarge
              mem_488_gb:
                display_name: 488 GB RAM, ~63 CPUs
                description: ~63 CPUs always available
                allowed_groups:
                - geolab:power
                kubespawner_override:
                  mem_guarantee: 523839830228
                  mem_limit: 523839830228
                  cpu_guarantee: 62.575
                  cpu_limit: 62.575
                  node_selector:
                    node.kubernetes.io/instance-type: r5.16xlarge
      - display_name: NVIDIA Tesla T4, ~16 GB, ~4 CPUs
        description: Start a container on a dedicated node with a GPU
        slug: gpu
        allowed_groups:
        - geolab:dev
        - geolab:power
        profile_options:
          image:
            display_name: Image
            dynamic_image_building:
              enabled: true
            unlisted_choice:
              enabled: true
              display_name: Custom image
              validation_regex: ^.+:.+$
              validation_message: Must be a publicly available docker image of form <image-name>:<tag>
              kubespawner_override:
                image: '{value}'
            choices:
              tensorflow:
                display_name: Pangeo Tensorflow ML Notebook
                slug: tensorflow
                kubespawner_override:
                  image: quay.io/pangeo/ml-notebook:2025.07.09
              pytorch:
                display_name: Pangeo PyTorch ML Notebook
                default: true
                slug: pytorch
                kubespawner_override:
                  image: quay.io/pangeo/pytorch-notebook:2025.05.22
        kubespawner_override:
          environment:
            NVIDIA_DRIVER_CAPABILITIES: compute,utility
          mem_limit:
          mem_guarantee: 14G
          node_selector:
            node.kubernetes.io/instance-type: g4dn.xlarge
          extra_resource_limits:
            nvidia.com/gpu: '1'

    scheduling:
      userScheduler:
        enabled: true
  jupyterhub-home-nfs:
    enabled: true
    eks:
      enabled: true
  jupyterhub-groups-exporter:
    config:
      groupsExporter:
        allowed_groups:
        - geolab
        - geolab:dev
        - geolab:power
  binderhub-service:
    enabled: true
    networkPolicy:
      enabled: true
    dockerApi:
      nodeSelector:
        2i2c/hub-name: binder
    config:
      KubernetesBuildExecutor:
        node_selector:
          node.kubernetes.io/instance-type: r5.xlarge
      BinderHub:
        image_prefix: quay.io/imagebuilding-non-gcp-hubs/earthscope-binder-
      DockerRegistry:
        url: &url https://quay.io
        username: &username imagebuilding-non-gcp-hubs+image_builder
    buildPodsRegistryCredentials:
      server: *url
      username: *username
