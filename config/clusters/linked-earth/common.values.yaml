basehub:
  nfs:
    enabled: true
    pv:
      mountOptions:
        - soft
        - noatime
      # Google FileStore IP
      serverIP: 10.58.206.114
      # Name of Google Filestore share
      baseShareName: /homes/
  jupyterhub:
    proxy:
      https:
        enabled: false
    custom:
      2i2c:
        add_staff_user_ids_to_admin_users: true
        add_staff_user_ids_of_type: "google"
      homepage:
        templateVars:
          org:
            name: LinkedEarth
            url: https://linked.earth/
            logo_url: https://linked.earth/_images/LinkedEarth_small.png
          designed_by:
            name: 2i2c
            url: https://2i2c.org
          operated_by:
            name: 2i2c
            url: https://2i2c.org
          funded_by:
            name: ""
            url: ""
    hub:
      config:
        JupyterHub:
          authenticator_class: cilogon
        Authenticator:
          # We do not define allowed_users here since only usernames matching this regex will be allowed to login into the hub.
          # Ref: https://jupyterhub.readthedocs.io/en/stable/api/auth.html#jupyterhub.auth.Authenticator.username_pattern
          username_pattern: '^(.+@2i2c\.org|deployment-service-check)$'
        CILogonAuthenticator:
          username_claim: "email"
          allowed_idps:
            - 2i2c.org
    singleuser:
      image:
        # User image repo: https://quay.io/repository/linkedearth/pyleoclim
        name: quay.io/linkedearth/pyleoclim
        tag: "latest"
      profileList:
        # The mem-guarantees are here so k8s doesn't schedule other pods
        # on these nodes. They need to be just under total allocatable
        # RAM on a node, not total node capacity. Values calculated using
        # https://learnk8s.io/kubernetes-instance-calculator
        - display_name: "Small"
          description: 5GB RAM, 2 CPUs
          default: true
          kubespawner_override:
            mem_limit: 7G
            mem_guarantee: 4.5G
            node_selector:
              node.kubernetes.io/instance-type: n1-standard-2
        - display_name: Medium
          description: 11GB RAM, 4 CPUs
          kubespawner_override:
            mem_limit: 15G
            mem_guarantee: 11G
            node_selector:
              node.kubernetes.io/instance-type: n1-standard-4
        - display_name: Large
          description: 24GB RAM, 8 CPUs
          kubespawner_override:
            mem_limit: 30G
            mem_guarantee: 24G
            node_selector:
              node.kubernetes.io/instance-type: n1-standard-8
        - display_name: Huge
          description: 52GB RAM, 16 CPUs
          kubespawner_override:
            mem_limit: 60G
            mem_guarantee: 52G
            node_selector:
              node.kubernetes.io/instance-type: n1-standard-16
      initContainers:
        # Need to explicitly fix ownership here, since EFS doesn't do anonuid
        - name: volume-mount-ownership-fix
          image: busybox
          command:
            [
              "sh",
              "-c",
              "id && chown 1000:1000 /home/jovyan && ls -lhd /home/jovyan",
            ]
          securityContext:
            runAsUser: 0
          volumeMounts:
            - name: home
              mountPath: /home/jovyan
              subPath: "{username}"
dask-gateway:
  gateway:
    backend:
      scheduler:
        cores:
          request: 0.8
          limit: 1
        memory:
          request: 1G
          limit: 2G
