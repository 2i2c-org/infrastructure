nfs:
  enabled: true
  pv:
    enabled: true
    # from https://docs.aws.amazon.com/efs/latest/ug/mounting-fs-nfs-mount-settings.html
    mountOptions:
    - rsize=1048576
    - wsize=1048576
    - timeo=600
    - soft   # We pick soft over hard, so NFS lockups don't lead to hung processes
    - retrans=2
    - noresvport
jupyterhub:
  custom:
    2i2c:
      add_staff_user_ids_to_admin_users: true
      add_staff_user_ids_of_type: github
    homepage:
      templateVars:
        org:
          name: bnext-bio
          logo_url: https://bnext.bio/assets/logo_1752007791752-BRLYypJ5.png
          url: https://bnext.bio/
        designed_by:
          name: 2i2c
          url: https://2i2c.org
        operated_by:
          name: 2i2c
          url: https://2i2c.org
        funded_by:
          name: b.next
          url: https://bnext.bio/
  hub:
    allowNamedServers: true
    loadRoles:
      user:
        scopes:
        - self
        - shares!user
        - read:users:name
        - list:users
    config:
      KubeSpawner:
        image_pull_policy: Always
      JupyterHub:
        authenticator_class: github
      GitHubOAuthenticator:
        allowed_organizations:
        - 2i2c-org:hub-access-for-2i2c-staff
        - 2i2c-org:engineering
        - nucleus-eng:hub-access
        - nucleus-eng:nucleus-eng-hub-access
        - nucleus-eng:devcells-all-nodes
        - nucleus-eng:devcells-chicago-node
        - nucleus-eng:devcells-london-node
      Authenticator:
        admin_users:
        - antonjs
        - antonrmolina
      Spawner:
        # Allow these sharing scopes for oauth tokens issued by the oauth client
        oauth_client_allowed_scopes:
        - shares!server
        - servers!server
        - read:users:name
        - list:users
    extraConfig:
      000-volumes-and-volume-mounts-as-dict: |
        # The base jupyterhub config in zero-to-jupyterhub defines
        # volumes and volume_mounts as lists.
        # But we can't add new volumes or volume_mounts to the list
        # as that replaces the entire list.
        # So we convert them to dictionaries, which allows us to
        # add new volumes and volume_mounts as needed.
        if isinstance(c.KubeSpawner.volumes, list):
          existing_volumes = c.KubeSpawner.volumes
          c.KubeSpawner.volumes = {}
          for volume in existing_volumes:
            c.KubeSpawner.volumes[volume["name"]] = volume
        if isinstance(c.KubeSpawner.volume_mounts, list):
          existing_volume_mounts = c.KubeSpawner.volume_mounts
          c.KubeSpawner.volume_mounts = {}
          for idx, volume_mount in enumerate(existing_volume_mounts):
            c.KubeSpawner.volume_mounts[f"{idx}-{volume_mount['name']}"] = volume_mount
      001-group-shared-directories: |
        projects = {
          "2i2c-org:hub-access-for-2i2c-staff": "hub-access-for-2i2c-staff",
          "nucleus-eng:hub-access": "nucleus-eng-hub-access",
          "nucleus-eng:devcells-london-node": "devcells-london-node",
          "nucleus-eng:devcells-chicago-node": "devcells-chicago-node",
          "nucleus-eng:devcells-all-nodes": "devcells-all-nodes"
        }

        for i, (group, project) in enumerate(projects.items()):
          c.KubeSpawner.group_overrides.update({
          f"0{i}-group-{project}": {
            "groups": [group],
            "spawner_override": {
              "volume_mounts": {
                f"0{i}-group-hub-access-for-2i2c-staff": {
                  "name": "home",
                  "mountPath": f"/home/jovyan/projects/{project}",
                  "subPath": f"_projects/{project}",
                  "readOnly": False
                },
              }
            },
          }
        })

  scheduling:
    userScheduler:
      enabled: true
  singleuser:
    defaultUrl: /lab
binderhub-service:
  enabled: true
    # Explicitly specify what nodes we want for our builds
    # Otherwise we may scale up a larger node than needed
  networkPolicy:
    enabled: true
  dockerApi:
    nodeSelector:
      node.kubernetes.io/instance-type: r5.xlarge
  config:
    KubernetesBuildExecutor:
      node_selector:
        node.kubernetes.io/instance-type: r5.xlarge
    DockerRegistry:
      url: &url https://quay.io
      username: &username imagebuilding-non-gcp-hubs+image_builder
  buildPodsRegistryCredentials:
    server: *url
    username: *username

jupyterhub-home-nfs:
  enabled: true
  eks:
    enabled: true
  prometheusExporter:
    enabled: true
