nfs:
  enabled: true
  pv:
    enabled: true
    # from https://docs.aws.amazon.com/efs/latest/ug/mounting-fs-nfs-mount-settings.html
    mountOptions:
    - rsize=1048576
    - wsize=1048576
    - timeo=600
    - soft   # We pick soft over hard, so NFS lockups don't lead to hung processes
    - retrans=2
    - noresvport
jupyterhub:
  custom:
    2i2c:
      add_staff_user_ids_to_admin_users: true
      add_staff_user_ids_of_type: github
    homepage:
      templateVars:
        org:
          name: bnext-bio
          logo_url: https://bnext.bio/assets/logo_1752007791752-BRLYypJ5.png
          url: https://bnext.bio/
        designed_by:
          name: 2i2c
          url: https://2i2c.org
        operated_by:
          name: 2i2c
          url: https://2i2c.org
        funded_by:
          name: b.next
          url: https://bnext.bio/
  hub:
    allowNamedServers: true
    loadRoles:
      user:
        scopes:
        - self
        - shares!user
        - read:users:name
        - list:users
    config:
      KubeSpawner:
        image_pull_policy: Always
      JupyterHub:
        authenticator_class: github
      GitHubOAuthenticator:
        allowed_organizations:
        - 2i2c-org:hub-access-for-2i2c-staff
        - nucleus-eng:hub-access
        - nucleus-eng:nucleus-eng-hub-access
        - nucleus-eng:devcells-all-nodes
        - nucleus-eng:devcells-chicago-node
        - nucleus-eng:devcells-london-node
        - nucleus-eng:bnext
        - nucleus-eng:metapure
      Authenticator:
        admin_users:
        - antonjs
        - antonrmolina
      Spawner:
        # Allow these sharing scopes for oauth tokens issued by the oauth client
        oauth_client_allowed_scopes:
        - shares!server
        - servers!server
        - read:users:name
        - list:users
    extraConfig:
      000-volumes-and-volume-mounts-as-dict: |
        # The base jupyterhub config in zero-to-jupyterhub defines
        # volumes and volume_mounts as lists.
        # But we can't add new volumes or volume_mounts to the list
        # as that replaces the entire list.
        # So we convert them to dictionaries, which allows us to
        # add new volumes and volume_mounts as needed.
        if isinstance(c.KubeSpawner.volumes, list):
          existing_volumes = c.KubeSpawner.volumes
          c.KubeSpawner.volumes = {}
          for volume in existing_volumes:
            c.KubeSpawner.volumes[volume["name"]] = volume
        if isinstance(c.KubeSpawner.volume_mounts, list):
          existing_volume_mounts = c.KubeSpawner.volume_mounts
          c.KubeSpawner.volume_mounts = {}
          for idx, volume_mount in enumerate(existing_volume_mounts):
            c.KubeSpawner.volume_mounts[f"{idx}-{volume_mount['name']}"] = volume_mount
      001-group-shared-directories: |
        groups = [
            "2i2c-org:hub-access-for-2i2c-staff",
            ("nucleus-eng:hub-access", "nucleus-eng-hub-access"),
            "nucleus-eng:devcells-london-node",
            "nucleus-eng:devcells-chicago-node",
            "nucleus-eng:devcells-all-nodes",
            "nucleus-eng:curvenote",
            "nucleus-eng:metapure",
        ]

        c.KubeSpawner.group_overrides = {
            # Don't worry about escaping â€” the only requirement is these keys are unique
            f"{i:0>2}-group-{group}": {
                "groups": [group],
                "spawner_override": {
                    "volume_mounts": {
                        f"{i:0>2}-group-{group}": {
                            "name": "home",
                            "mountPath": f"/home/jovyan/projects/{name}",
                            "subPath": f"_projects/{name}",
                            "readOnly": False,
                        }
                    }
                },
            }
            for i, (group, name) in enumerate(
                # 1. Map "foo:bar" shorthand onto ("foo:bar", "bar")
                # 2. Support hard-coded exception for path if defined as a tuple ("foo:bar", "bar")
                (p, p.split(":", 1)[1]) if isinstance(p, str) else p
                for p in (groups)
            )
        }

  scheduling:
    userScheduler:
      enabled: true
  singleuser:
    defaultUrl: /lab
binderhub-service:
  enabled: true
    # Explicitly specify what nodes we want for our builds
    # Otherwise we may scale up a larger node than needed
  networkPolicy:
    enabled: true
  dockerApi:
    nodeSelector:
      node.kubernetes.io/instance-type: r5.xlarge
  config:
    KubernetesBuildExecutor:
      node_selector:
        node.kubernetes.io/instance-type: r5.xlarge
    DockerRegistry:
      url: &url https://quay.io
      username: &username imagebuilding-non-gcp-hubs+image_builder
  buildPodsRegistryCredentials:
    server: *url
    username: *username
